---
title: "Modeling with Caret"
output:
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: console
---

**This document serves as a record of different attempts to model match outcomes using the 'caret' package.**

```{r setup, echo=F, message=F, warning=F}
library(dplyr)
library(zoo)
library(caret)
library(RANN)
library(tidyr)
library(ggplot2)
library(broom)
library(nnet)
source(file = "engineering_seriea_design_matrix trailing.R") # runs in under 2 seconds
set.seed(5590)
```


First step is to remove extraneous factor variables (game_id,season,round) and impute missing records

```{r Preprocess, echo=F}
# Imputing missing values with bagImpute (form for newly promoted teams)
DF <- DF_trailing %>% select(-game_id,-season,-round,-points)
ppi <- preProcess(DF,method = "bagImpute")
DF_Imputed <- predict(ppi,DF)

```


Nesting the larger dataset into a list of dataframes for each individual team
```{r Nesting Data}
# Nesting data by team - creates a list of dataframes, one for each team's results.
teams <- unique(DF_Imputed$Team)
nested_DF <- list()

for (i in teams){
  temp_df <- DF_Imputed %>% filter(Team==i)
  nested_DF[[i]] <- temp_df
}


nested_DF_orig <- nested_DF

# Filtering to 2018-19 teams only
# Pescara, HellasVerona, Crotone, Benevento, Palermo
nested_DF <- nested_DF[c("Roma","Juventus","Milan","Atalanta","Bologna","Chievoverona","Empoli",
                         "Genoa","Lazio","Napoli","Inter","Cagliari","Fiorentina","Sampdoria",
                         "Sassuolo","Torino","Udinese","Spal","Parma","Frosinone")]

# for(i in 1:length(nested_DF)){ print(dim(nested_DF[[i]]))}

# Filtering out Parma, Frosinone which have no data from previous Serie A season

nested_DF <- nested_DF[c("Roma","Juventus","Milan","Atalanta","Bologna","Chievoverona","Empoli",
                         "Genoa","Lazio","Napoli","Inter","Cagliari","Fiorentina","Sampdoria",
                         "Sassuolo","Torino","Udinese","Spal")]

# printing out the number of records for each DF. Notice that teams that have been in SerieA for the past 3+ years will have 100 records, while Empoli and Spal only have 63 records
for(i in 1:length(nested_DF)){ print(dim(nested_DF[[i]]))}


```


Modeling outcomes using multinom method from the nnet package:
```{r Loop Pred, error=F, warning=F, message=F}

# Team part will take all of the individual df's in nested_DF and break them into Train/Test Sets
team_part <- list()

for(i in names(nested_DF)){
  
  temp <- nested_DF[[i]]
  obs<-nrow(temp)
  
  # Test set is the final season (last 24 observations)
  temp_test <- temp[(obs-23):obs, ]
  
  # Train set is all observations that come before
  temp_train <- temp[1:(obs-23), ] 

  Out<-list(i,temp_train,temp_test)  
  
  team_part[[i]] <- Out
}


# Create Timeslices TimeControl
my_TimeControl <- trainControl(method="timeslice",
                               initialWindow = 10,
                               horizon=1,
                               fixedWindow = TRUE)

# Creating a second list which will hold the team name, model fit, prediction, and accuracy
team_model <- list()
x <- proc.time() 
for(i in 1:length(team_part)){

  temp <- team_part[[i]]
  
  name <- temp[[1]]
  train <- temp[[2]]
  test <- temp[[3]]
  
  # Training RF
  rfFit1 <- train(result~., data=train,
                  method="multinom",
                  trControl=my_TimeControl)
  
  
  # Prediction
  rfRes1 <- predict(rfFit1,
                    #type = "prob", 
                    newdata = test)
  actual<- test %>% select(result)
  
  # Results in a confusion matrix
  Results<-confusionMatrix(rfRes1, as.factor(actual$result))
  
  team_model[[i]] <- list(name,rfFit1,rfRes1,Results)

}

y <- proc.time() 

y-x # about 3.5 minutes to run


```




```{r Results from RF}

# Extracting Team name, accuracy

rf_results <- list()
for(i in 1:length(team_model)){

  name<- team_model[[i]][[1]]
  acc <- team_model[[i]][[4]]$overall[[1]]  

  r <- as.data.frame(acc)

  rf_results[[i]] <- r
  }

rf_final <- bind_rows(rf_results)
rownames(rf_final) <- names(team_part)

rf_final %>% arrange(desc(acc))


```

```{r Visualizaing Team-by-Team accuracy}


weekly_results <- list()

for(i in 1:18){
  weekly_pred <- team_model[[i]][[3]]
  weekly_actual <- team_part[[i]][[3]]$result  
  
  weekly_acc <- weekly_pred==weekly_actual
  
  weekly_results[[i]] <- as.data.frame(weekly_acc)
  
}

weekly_results <- bind_cols(weekly_results)
colnames(weekly_results) <- names(nested_DF)

weekly_results$Round <- 1:24

weekly_results_long<-gather(weekly_results,"Team","Prediction",1:18)

weekly_results_perc <- weekly_results_long %>% group_by(Round) %>% summarise(Prediction_Perc=mean(Prediction))

ggplot(weekly_results_long, aes(x=Round,y=Team,fill=Prediction)) + geom_tile() +  theme_minimal() +
  ggtitle("Weekly Accuracy by Team")

ggplot(weekly_results_perc, aes(x=Round,y=Prediction_Perc)) + geom_line() + 
  geom_hline(yintercept = mean(weekly_results_perc$Prediction_Perc), color="red") +
  theme_minimal() + ggtitle("Weekly Accuracy") 

# overall avg weekly accuracy is 44% 


```




